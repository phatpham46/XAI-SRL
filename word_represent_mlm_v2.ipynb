{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T08:15:47.229618Z","iopub.status.busy":"2024-05-13T08:15:47.229183Z","iopub.status.idle":"2024-05-13T08:15:49.270162Z","shell.execute_reply":"2024-05-13T08:15:49.269184Z","shell.execute_reply.started":"2024-05-13T08:15:47.229584Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'SRLPredictionEasel'...\n","remote: Enumerating objects: 466, done.\u001b[K\n","remote: Counting objects: 100% (87/87), done.\u001b[K\n","remote: Compressing objects: 100% (61/61), done.\u001b[K\n","remote: Total 466 (delta 34), reused 62 (delta 24), pack-reused 379\u001b[K\n","Receiving objects: 100% (466/466), 3.05 MiB | 14.58 MiB/s, done.\n","Resolving deltas: 100% (269/269), done.\n"]}],"source":["!git clone https://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@github.com/phatpham46/SRLPredictionEasel.git"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T08:16:15.791701Z","iopub.status.busy":"2024-05-13T08:16:15.791332Z","iopub.status.idle":"2024-05-13T08:16:32.177028Z","shell.execute_reply":"2024-05-13T08:16:32.175787Z","shell.execute_reply.started":"2024-05-13T08:16:15.791669Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.26.4)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\n","Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=f5767f562373fba0ab7578e6662f52668ff3eea7d41a94f46e740f0f8bf63596\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n"]}],"source":["!pip install seqeval"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T08:16:32.179722Z","iopub.status.busy":"2024-05-13T08:16:32.179345Z","iopub.status.idle":"2024-05-13T08:16:35.906734Z","shell.execute_reply":"2024-05-13T08:16:35.905933Z","shell.execute_reply.started":"2024-05-13T08:16:32.179686Z"},"trusted":true},"outputs":[],"source":["import os\n","from pathlib import Path\n","import pandas as pd\n","import torch "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T08:16:40.022357Z","iopub.status.busy":"2024-05-13T08:16:40.021457Z","iopub.status.idle":"2024-05-13T08:16:47.886237Z","shell.execute_reply":"2024-05-13T08:16:47.885438Z","shell.execute_reply.started":"2024-05-13T08:16:40.022321Z"},"trusted":true},"outputs":[],"source":["import json\n","import sys\n","sys.path.append('/kaggle/working/SRLPredictionEasel/MLM')\n","from MLM.mlm_utils.transform_func import get_files"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T08:16:53.269537Z","iopub.status.busy":"2024-05-13T08:16:53.268927Z","iopub.status.idle":"2024-05-13T08:16:53.276913Z","shell.execute_reply":"2024-05-13T08:16:53.275732Z","shell.execute_reply.started":"2024-05-13T08:16:53.269504Z"},"trusted":true},"outputs":[],"source":["def get_sum_avg(last_hidden_state, pos_tag_id):\n","    \n","    # lhds = 32 128 768 \n","    # pos tag = 32 128\n","    \n","    b_sum_vector = []\n","    b_avg_vector = []\n","    \n","   \n","    for index in range(len(pos_tag_id)):\n","        masked_index = torch.where(pos_tag_id[index] != 0)\n","        sum_vector_present = torch.sum(last_hidden_state[index][masked_index], 0)\n","        avg_vector_present = torch.mean(last_hidden_state[index][masked_index], 0)\n","        \n","        assert sum_vector_present.shape == avg_vector_present.shape == torch.Size([768])\n","        \n","        b_sum_vector.append(sum_vector_present)\n","        b_avg_vector.append(avg_vector_present)\n","    return b_sum_vector, b_avg_vector\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T08:20:20.918360Z","iopub.status.busy":"2024-05-13T08:20:20.917278Z","iopub.status.idle":"2024-05-13T08:20:20.929584Z","shell.execute_reply":"2024-05-13T08:20:20.928534Z","shell.execute_reply.started":"2024-05-13T08:20:20.918321Z"},"trusted":true},"outputs":[],"source":["\n","def content_word_batch(b_origin_uid, b_origin_id, b_pos_tag_id, b_sum_vector, b_avg_vector):\n","    '''\n","    input: \n","    pos_tag_id: batch of pos_tag_id \n","    return: batch of type of masked word\n","    '''\n","    lists = {\"NOUN\": [], \"VERB\": [], \"ADJ\": [], \"ADV\": []}\n","    features = []\n","    \n","    for origin_uid, pos_tag, origin_id, sum_vector, avg_vector in zip(b_origin_uid, b_pos_tag_id, b_origin_id, b_sum_vector, b_avg_vector):\n","        masked_index = torch.where(pos_tag != 0)\n","    \n","        if pos_tag[masked_index[0][0].item()] == 1:\n","            lists[\"NOUN\"].append({\"word\": origin_id[masked_index[0]], \"sum_vector\": sum_vector, \"avg_vector\": avg_vector})\n","        elif pos_tag[masked_index[0][0].item()] == 2:\n","            lists[\"VERB\"].append({\"word\": origin_id[masked_index[0]], \"sum_vector\": sum_vector, \"avg_vector\": avg_vector})\n","        elif pos_tag[masked_index[0][0].item()] == 3:\n","            lists[\"ADJ\"].append({\"word\": origin_id[masked_index[0]], \"sum_vector\": sum_vector, \"avg_vector\": avg_vector})\n","        elif pos_tag[masked_index[0][0].item()] == 4:\n","            lists[\"ADV\"].append({\"word\": origin_id[masked_index[0]], \"sum_vector\": sum_vector, \"avg_vector\": avg_vector})\n","\n","        feature = {\n","                \"origin_uid\": int(origin_uid.item()),\n","                \"origin_id\": origin_id.tolist(),\n","                \"pos_tag_id\": pos_tag.tolist(),\n","                \"word\": origin_id[masked_index[0]].tolist(), \n","                \"sum_vector\": sum_vector.tolist(), \n","                \"avg_vector\": avg_vector.tolist()}\n","        \n","        # f.write('{}\\n'.format(json.dumps(feature)))\n","        features.append(feature)\n","    return lists, features"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T08:20:25.321392Z","iopub.status.busy":"2024-05-13T08:20:25.320721Z","iopub.status.idle":"2024-05-13T08:20:40.872536Z","shell.execute_reply":"2024-05-13T08:20:40.871583Z","shell.execute_reply.started":"2024-05-13T08:20:25.321358Z"},"trusted":true},"outputs":[],"source":["sys.path.append('/kaggle/working/SRLPredictionEasel/')\n","\n","from SRL.model import multiTaskModel\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","def load_params(model_file):\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    # Load finetuned model\n","    loadedDict = torch.load(model_file, map_location=torch.device(device))\n","\n","    taskParams = loadedDict['task_params']\n","    allParams = {}\n","    allParams['task_params'] = taskParams\n","    allParams['gpu'] = torch.cuda.is_available()\n","\n","    # dummy values\n","    allParams['num_train_steps'] = 10\n","    allParams['warmup_steps'] = 0\n","    allParams['learning_rate'] = 2e-5\n","    allParams['epsilon'] = 1e-8\n","\n","    return allParams, loadedDict\n","\n","model_file = Path('/mnt/c/Users/Phat Pham/Documents/THESIS/SRLPredictionEasel/output/multi_task_model_9_13050.pt')\n","# model_file = Path('/kaggle/input/finetunedsrl/pytorch/finetunesrl/1/multi_task_model_9_13050.pt')\n","allParams, loadedDict = load_params(model_file)\n","model = multiTaskModel(allParams)\n","model.load_multi_task_model(loadedDict)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T08:20:40.874374Z","iopub.status.busy":"2024-05-13T08:20:40.874027Z","iopub.status.idle":"2024-05-13T08:20:40.884723Z","shell.execute_reply":"2024-05-13T08:20:40.883737Z","shell.execute_reply.started":"2024-05-13T08:20:40.874349Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","def list_content_word(dataloader, wrtFile):\n","    \n","    content_word_lists = {\"NOUN\": [], \"VERB\": [], \"ADJ\": [], \"ADV\": []}\n","    len_lists = {\"NOUN\": 0, \"VERB\": 0, \"ADJ\": 0, \"ADV\": 0}\n","    \n","    with open(wrtFile, 'w') as f:\n","        for batch in tqdm(dataloader, total = len(dataloader)):\n","            batch = tuple(t.to(device) if isinstance(t, torch.Tensor) else t for t in batch)\n","        \n","            origin_uid, origin_id, attention_mask, token_type_ids, pos_tag_id = batch\n","            with torch.no_grad():\n","                outputs_model, _ = model.network(origin_id, token_type_ids, attention_mask, 0, 'conllsrl')\n","                last_hidden_states = outputs_model[0]\n","                sum_vector, avg_vector = get_sum_avg(last_hidden_states, pos_tag_id)\n","                \n","            b_content_word, b_feature = content_word_batch(origin_uid, origin_id, pos_tag_id, sum_vector, avg_vector)\n","            \n","            for feature in b_feature:\n","                f.write('{}\\n'.format(json.dumps(feature)))\n","                \n","                \n","            for key, value in b_content_word.items() :\n","                len_lists[key] += len(value)  \n","                content_word_lists[key] += value\n","             \n","    return content_word_lists, len_lists\n","# mỗi file sẽ lấy ra word emb cua tung cau trong file roi dong thoi tao list chung de luu content word "]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T08:41:22.836554Z","iopub.status.busy":"2024-05-13T08:41:22.835559Z","iopub.status.idle":"2024-05-13T08:41:22.844724Z","shell.execute_reply":"2024-05-13T08:41:22.843813Z","shell.execute_reply.started":"2024-05-13T08:41:22.836516Z"},"trusted":true},"outputs":[],"source":["import torch\n","from MLM.mlm_utils.pertured_dataset import PerturedDataset\n","\n","from MLM.mlm_utils.transform_func import check_data_dir\n","def process_files(dataDir, wriDir):\n","    files = get_files(dataDir)\n","    check_data_dir(wriDir, auto_create=True)\n","    \n","    def process_file(file, wriDir):\n","        print(\"Preprocessing file...\", file)\n","        dataset = PerturedDataset(\n","                        file_name=dataDir/file,\n","                        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n","\n","        dataloader = dataset.generate_batches(\n","                        dataset= dataset,\n","                        batch_size=32)\n","        \n","        wrtFile = os.path.join(wriDir, file)\n","        \n","        content_word_file, len = list_content_word(dataloader, wrtFile)\n","        return content_word_file, len\n","    \n","    res_files = map(lambda x: process_file(x, wriDir), files)\n","    content_word_files = list(zip(*res_files))\n","    return content_word_files[0]"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T08:41:25.652172Z","iopub.status.busy":"2024-05-13T08:41:25.651126Z","iopub.status.idle":"2024-05-13T08:49:32.582891Z","shell.execute_reply":"2024-05-13T08:49:32.581688Z","shell.execute_reply.started":"2024-05-13T08:41:25.652137Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Preprocessing file... mlm_abolish_full.json\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 32/32 [02:33<00:00,  4.79s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Preprocessing file... mlm_alter_full.json\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 49/49 [03:34<00:00,  4.38s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Preprocessing file... mlm_begin_1_full.json\n"]},{"name":"stderr","output_type":"stream","text":[" 74%|███████▍  | 51/69 [03:41<01:09,  3.86s/it]"]}],"source":["from pathlib import Path\n","# Path('/kaggle/working/word_present_each_file/').mkdir(parents=True, exist_ok=True)\n","# Path('/kaggle/working/list_content_word/').mkdir(parents=True, exist_ok=True)\n","\n","# dataDir = Path('/kaggle/input/mlm-data-preparation/mlm_output')\n","# wriDir = Path('/kaggle/working/word_present_each_file/')\n","dataDir = Path('/mnt/c/Users/Phat Pham/Documents/THESIS/SRLPredictionEasel/MLM/data_mlm/process_folder/mlm_output')\n","wriDir = Path('/mnt/c/Users/Phat Pham/Documents/THESIS/SRLPredictionEasel/MLM/data_mlm/process_folder/word_present_each_file_v3')\n","all_list_word = process_files(dataDir, wriDir)\n","    "]},{"cell_type":"markdown","metadata":{},"source":["## Create and save list content word "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T08:26:28.065068Z","iopub.status.busy":"2024-05-13T08:26:28.064170Z","iopub.status.idle":"2024-05-13T08:26:28.073486Z","shell.execute_reply":"2024-05-13T08:26:28.072387Z","shell.execute_reply.started":"2024-05-13T08:26:28.065026Z"},"trusted":true},"outputs":[{"data":{"text/plain":["dict_keys(['NOUN', 'VERB', 'ADJ', 'ADV'])"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["all_list_word[0].keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T08:49:32.597839Z","iopub.status.busy":"2024-05-13T08:49:32.597476Z","iopub.status.idle":"2024-05-13T09:40:19.536692Z","shell.execute_reply":"2024-05-13T09:40:19.535677Z","shell.execute_reply.started":"2024-05-13T08:49:32.597808Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Write NOUN to csv file successfully\n","Write VERB to csv file successfully\n","Write ADJ to csv file successfully\n","Write ADV to csv file successfully\n"]}],"source":["\n","# wriDir = '/kaggle/working/list_content_word/'\n","wriDir = '/mnt/c/Users/Phat Pham/Documents/THESIS/SRLPredictionEasel/MLM/data_mlm/process_folder/list_content_word_v3'\n","# write all list word to csv file \n","\n","df_list = {\"NOUN\": pd.DataFrame(), \"VERB\": pd.DataFrame(), \"ADJ\":pd.DataFrame(), \"ADV\": pd.DataFrame()}\n","for i in range(len(all_list_word)):\n","    for key, value in all_list_word[i].items():\n","        df = pd.DataFrame(value)\n","      \n","        df_list[key] = pd.concat([df_list[key], df], ignore_index=True)\n","       \n","for key in df_list.keys():\n","    df_list[key].to_csv(os.path.join(wriDir, '{}.csv'.format(key)), index = True)\n","    print(\"Write\", key, \"to csv file successfully\")"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-05-13T09:44:31.368013Z","iopub.status.busy":"2024-05-13T09:44:31.367540Z","iopub.status.idle":"2024-05-13T09:45:53.439996Z","shell.execute_reply":"2024-05-13T09:45:53.438848Z","shell.execute_reply.started":"2024-05-13T09:44:31.367975Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: kaggle/working/list_content_word/ (stored 0%)\n","  adding: kaggle/working/list_content_word/ADV.csv (deflated 83%)\n","  adding: kaggle/working/list_content_word/NOUN.csv (deflated 81%)\n","  adding: kaggle/working/list_content_word/ADJ.csv (deflated 81%)\n","  adding: kaggle/working/list_content_word/VERB.csv (deflated 82%)\n"]},{"data":{"text/html":["<a href='file.zip' target='_blank'>file.zip</a><br>"],"text/plain":["/kaggle/working/file.zip"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["!zip -r file.zip /kaggle/working/list_content_word\n","\n","from IPython.display import FileLink \n","FileLink(r'file.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import gc\n","# gc.collect()\n","# torch.cuda.empty_cache()\n","\n","# # convert to dataframe\n","# df = pd.DataFrame(list(test_dataset)[:100], columns=[\"token_id\", \"type_id\", \"attention\", \"label\"])\n","\n","# token_tensors = torch.from_numpy(np.array([x for x in df['token_id'].values], dtype = np.int32)).to(device)\n","# type_id_tensors =torch.from_numpy(np.array([x for x in df['type_id'].values], dtype = np.int32)).to(device)\n","# attn_tensors = torch.from_numpy(np.array([x for x in df['attention'].values], dtype = np.int32)).to(device)\n","# label_tensor = torch.from_numpy(np.array([x for x in df['label'].values], dtype = np.int32)).to(device)\n","# del test_dataset\n","\n","\n","# with torch.no_grad():\n","\n","#   outputs_model, _ = model.network(token_tensors, type_id_tensors, attn_tensors, 0, 'conllsrl')\n","#   last_hidden_states = outputs_model[0]\n","#   hidden_states = outputs_model[2]\n","\n","# # sum of last four layer\n","# word_embed_5 = torch.stack(hidden_states[-4:]).sum(0)\n","\n","# # concatenate last four layers\n","# word_embed_6 = torch.cat([hidden_states[i] for i in [-1,-2,-3,-4]], dim=-1)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4995431,"sourceId":8396879,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelInstanceId":39493,"sourceId":47166,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":4}
