{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('/mnt/c/Users/Phat Pham/Documents/THESIS/SRLPredictionEasel/MLM')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import dask.dataframe as dd\n",
    "\n",
    "def read_data(readPath):\n",
    "    df = pd.read_json(readPath, lines=True)\n",
    "    return df\n",
    "\n",
    "def read_data_dask(readPath):\n",
    "    df = dd.read_json(readPath, lines=True)\n",
    "    return df\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    # check if a and b are not list, convert it\n",
    "    if not isinstance(a, list):\n",
    "        a = ast.literal_eval(a)\n",
    "    if not isinstance(b, list):\n",
    "        b = ast.literal_eval(b)\n",
    "            \n",
    "    return round(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)), 4)\n",
    "\n",
    "\n",
    "def cosine_module(a, b, cosine_sum):\n",
    "    norm_array1 = np.linalg.norm(a)\n",
    "    norm_array2 = np.linalg.norm(b)\n",
    "    \n",
    "    module_similarity = 1 - (np.abs(norm_array1 - norm_array2) / (norm_array1 + norm_array2))\n",
    "    \n",
    "    return module_similarity * cosine_sum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_cosine_similarities(df_predicate, vector_type, df_content, metric = 'cosine'):\n",
    "    ''' cosine simimlarity matrix -> neg cosine sum, pos cosine sum'''\n",
    "    similarities = pd.DataFrame(index=df_predicate.index, columns=df_content.index)\n",
    "    \n",
    "    for i in df_predicate.index:\n",
    "        for j in df_content.index:\n",
    "            vec1 = df_predicate.at[i, '{}_vector'.format(vector_type)]\n",
    "            vec2 = df_content.at[j, '{}_vector'.format(vector_type)]\n",
    "            similarities.at[i, j] = cosine_sim(vec1, vec2)\n",
    "    # Convert to numeric type\n",
    "    similarities = similarities.apply(pd.to_numeric)\n",
    "    \n",
    "    print(\"Similarities shape: \", similarities.shape)\n",
    "    \n",
    "    # cosine -1\n",
    "    min_indices = similarities.idxmin(axis=1)\n",
    "    df_predicate.loc[:, \"neg_{}_{}\".format(metric, vector_type)] = df_content.loc[min_indices]['word'].values\n",
    "    df_predicate.loc[:, \"neg_value_{}_{}\".format(metric, vector_type)] = similarities.min(axis=1).values\n",
    "   \n",
    "    # cosine 0\n",
    "    pos_cos_sum_indices = np.abs(similarities).idxmin(axis=1)\n",
    "    df_predicate.loc[:, \"pos_{}_{}\".format(metric, vector_type)] = df_content.loc[pos_cos_sum_indices]['word'].values\n",
    "    df_predicate.loc[:, \"pos_value_{}_{}\".format(metric, vector_type)] = np.abs(similarities).min(axis=1).values  # absolute value\n",
    "    \n",
    "    # separate neg_value_cosine_sum and pos_value_cosine_value into dataframe with 2 column\n",
    "    val_df = df_predicate[['neg_value_{}_{}'.format(metric, vector_type), 'neg_{}_{}'.format(metric, vector_type), 'pos_value_{}_{}'.format(metric, vector_type), 'pos_{}_{}'.format(metric, vector_type)]]\n",
    "    # drop 2 columns from df_predicate\n",
    "    df_predicate.drop(['neg_value_{}_{}'.format(metric, vector_type), 'pos_value_{}_{}'.format(metric, vector_type)], axis=1, inplace=True)\n",
    "    return df_predicate, val_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_nonzero(lst):\n",
    "    nonzero_elements = filter(lambda x: x != 0, lst)\n",
    "    return next(nonzero_elements, 0)\n",
    "\n",
    "\n",
    "def preprocess_df_predicate(df_predicate):\n",
    "    \n",
    "    df_predicate['tag_id'] = df_predicate['pos_tag_id'].apply(first_nonzero) \n",
    "   \n",
    "    return df_predicate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_word(df_predicate, df_noun, df_verb, df_adj, df_adv):\n",
    "    \n",
    "    # filter df with tag_id = 1\n",
    "    predicate_noun = df_predicate[df_predicate['tag_id'] == 1]\n",
    "    noun = compute_cosine_similarities(predicate_noun, 'sum', df_noun, 'cosine')\n",
    "    \n",
    "    predicate_verb = df_predicate[df_predicate['tag_id'] == 2]\n",
    "    verb = compute_cosine_similarities(predicate_verb, 'sum', df_verb, metric = 'cosine')\n",
    "    \n",
    "    predicate_adj = df_predicate[df_predicate['tag_id'] == 3]\n",
    "    adj = compute_cosine_similarities(predicate_adj, 'sum', df_adj, metric = 'cosine')\n",
    "    \n",
    "    predicate_adv = df_predicate[df_predicate['tag_id'] == 4]\n",
    "    adv = compute_cosine_similarities(predicate_adv, 'sum', df_adv, metric = 'cosine')\n",
    "    \n",
    "    res_df = pd.concat([noun, verb, adj, adv])\n",
    "   \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {\n",
    "    \"noun\": \"./data_mlm/process_folder/list_content_word_v2/NOUN.json\",\n",
    "    \"verb\": \"./data_mlm/process_folder/list_content_word_v2/VERB.json\",\n",
    "    \"adj\": \"./data_mlm/process_folder/list_content_word_v2/ADJ.json\",\n",
    "    \"adv\": \"./data_mlm/process_folder/list_content_word_v2/ADV.json\"\n",
    "}\n",
    "\n",
    "# df_noun = read_data_dask(\"./data_mlm/process_folder/list_content_word_v2/NOUN.json\")\n",
    "# df_verb = read_data_dask(file_paths[\"verb\"])\n",
    "# df_adj = read_data(file_paths[\"adj\"])\n",
    "# df_adv = read_data_dask(file_paths[\"adv\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_file = \"./data_mlm/process_folder/word_present_each_file/mlm_abolish_full.json\"\n",
    "\n",
    "df_predicate = read_data(predicate_file)\n",
    "\n",
    "df = preprocess_df_predicate(df_predicate)\n",
    "df_adv = read_data_dask(file_paths[\"adv\"])\n",
    "pd.options.mode.copy_on_write = True\n",
    "predicate_verb = df[df['tag_id'] == 2]\n",
    "\n",
    "    \n",
    "adv, val_df = compute_cosine_similarities(predicate_verb.iloc[:, :10], vector_type='sum', df_content=df_adv.head(40), metric = 'cosine')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, n_splits):\n",
    "    # Get the number of partitions\n",
    "    # n_partitions = df.npartitions\n",
    "    \n",
    "    # # Compute how many partitions per split\n",
    "    # partitions_per_split = n_partitions // n_splits\n",
    "    \n",
    "    # # Split the dataframe into n_splits\n",
    "    # dfs = []\n",
    "    # for i in range(n_splits):\n",
    "    #     start = i * partitions_per_split\n",
    "    #     end = (i + 1) * partitions_per_split if i < n_splits - 1 else n_partitions\n",
    "    #     dfs.append(df.partitions[start:end])\n",
    "    df_split_1 = dd.read_parquet('./split_data/split_1.parquet')\n",
    "    df_split_2 = dd.read_parquet('./split_data/split_2.parquet')\n",
    "    df_split_3 = dd.read_parquet('./split_data/split_3.parquet')\n",
    "    return df_split_1, df_split_2, df_split_3\n",
    "\n",
    "\n",
    "def select_noun_word(df_predicate, vector_type, df_noun, metric = 'cosine'):\n",
    "    dfs = split_dataframe(df_noun, 3)\n",
    "    pd.options.mode.copy_on_write = True\n",
    "    val_df1 = compute_cosine_similarities(df_predicate, vector_type, dfs[0].iloc[:, :10].compute(), metric)[1]\n",
    "    val_df2 = compute_cosine_similarities(df_predicate, vector_type, dfs[1].iloc[:, :10].compute(), metric)[1]\n",
    "    val_df3 = compute_cosine_similarities(df_predicate, vector_type, dfs[2].iloc[:, :10].compute(), metric)[1]\n",
    "    \n",
    "    # merge 3 val_df into one with axis 1 and get the min value of each row\n",
    "    concat_df = pd.concat([val_df1, val_df2, val_df3], axis=1)\n",
    "    \n",
    "    concat_df_neg  = concat_df.filter(like='neg_value_{type}')\n",
    "    concat_df_neg.columns = ['neg_value_{type}_1', 'neg_value_{type}_2', 'neg_value_{type}_3']\n",
    "    \n",
    "    \n",
    "    word_cols = concat_df.filter(like='neg_{type}')\n",
    "    word_cols.columns = ['neg_{type}_1', 'neg_{type}_2', 'neg_{type}_3']\n",
    "    \n",
    "    \n",
    "    min_val_indices = concat_df_neg.columns.get_indexer(concat_df_neg.idxmin(axis=1))\n",
    "    df_predicate.loc[:, \"neg_{}\".format(metric)] =  word_cols.apply(lambda row: row.iloc[min_val_indices[row.name]], axis=1)\n",
    "    \n",
    "    return df_predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicate_file = \"./data_mlm/process_folder/word_present_each_file/mlm_abolish_full.json\"\n",
    "\n",
    "df_predicate = read_data(predicate_file)\n",
    "df = preprocess_df_predicate(df_predicate)\n",
    "predicate_verb = df[df['tag_id'] == 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = select_noun_word(predicate_verb.iloc[:, :10], 'sum', None, 'cosine')\n",
    "aaa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split_1 = dd.read_parquet('./split_data/split_1.parquet')\n",
    "adv, val_df = compute_cosine_similarities(predicate_verb[:10], vector_type='sum', df_content=df_split_1.compute(), metric = 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_uid</th>\n",
       "      <th>origin_id</th>\n",
       "      <th>pos_tag_id</th>\n",
       "      <th>word</th>\n",
       "      <th>sum_vector</th>\n",
       "      <th>avg_vector</th>\n",
       "      <th>tag_id</th>\n",
       "      <th>neg_cosine_sum</th>\n",
       "      <th>pos_cosine_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 170, 176, 118, 1106, 118, 170, 6468, 112...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[8632]</td>\n",
       "      <td>[-0.6510494351387021, -0.20481480658054302, -0...</td>\n",
       "      <td>[-0.6510494351387021, -0.20481480658054302, -0...</td>\n",
       "      <td>2</td>\n",
       "      <td>[17957]</td>\n",
       "      <td>[17957]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>[101, 2393, 1643, 3246, 1110, 8632, 1118, 2791...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[8632]</td>\n",
       "      <td>[-0.106601975858211, 0.20928417146205902, -1.9...</td>\n",
       "      <td>[-0.106601975858211, 0.20928417146205902, -1.9...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2765]</td>\n",
       "      <td>[2765]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>[101, 2393, 1643, 3246, 1110, 8632, 1118, 2791...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, ...</td>\n",
       "      <td>[19717]</td>\n",
       "      <td>[-0.282490104436874, 0.22874452173709803, -2.2...</td>\n",
       "      <td>[-0.282490104436874, 0.22874452173709803, -2.2...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2765]</td>\n",
       "      <td>[2765]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>[101, 2393, 1643, 3246, 1108, 8632, 1118, 2791...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[8632]</td>\n",
       "      <td>[-0.212677419185638, 0.457284778356552, -2.437...</td>\n",
       "      <td>[-0.212677419185638, 0.457284778356552, -2.437...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2765]</td>\n",
       "      <td>[2765]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>[101, 2393, 1643, 3246, 1108, 8632, 1118, 2791...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, ...</td>\n",
       "      <td>[19717]</td>\n",
       "      <td>[-0.25142347812652505, 0.23143696784973103, -2...</td>\n",
       "      <td>[-0.25142347812652505, 0.23143696784973103, -2...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2765]</td>\n",
       "      <td>[2765]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    origin_uid                                          origin_id  \\\n",
       "5            0  [101, 170, 176, 118, 1106, 118, 170, 6468, 112...   \n",
       "17           2  [101, 2393, 1643, 3246, 1110, 8632, 1118, 2791...   \n",
       "18           2  [101, 2393, 1643, 3246, 1110, 8632, 1118, 2791...   \n",
       "23           3  [101, 2393, 1643, 3246, 1108, 8632, 1118, 2791...   \n",
       "24           3  [101, 2393, 1643, 3246, 1108, 8632, 1118, 2791...   \n",
       "\n",
       "                                           pos_tag_id     word  \\\n",
       "5   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   [8632]   \n",
       "17  [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   [8632]   \n",
       "18  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, ...  [19717]   \n",
       "23  [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   [8632]   \n",
       "24  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, ...  [19717]   \n",
       "\n",
       "                                           sum_vector  \\\n",
       "5   [-0.6510494351387021, -0.20481480658054302, -0...   \n",
       "17  [-0.106601975858211, 0.20928417146205902, -1.9...   \n",
       "18  [-0.282490104436874, 0.22874452173709803, -2.2...   \n",
       "23  [-0.212677419185638, 0.457284778356552, -2.437...   \n",
       "24  [-0.25142347812652505, 0.23143696784973103, -2...   \n",
       "\n",
       "                                           avg_vector  tag_id neg_cosine_sum  \\\n",
       "5   [-0.6510494351387021, -0.20481480658054302, -0...       2        [17957]   \n",
       "17  [-0.106601975858211, 0.20928417146205902, -1.9...       2         [2765]   \n",
       "18  [-0.282490104436874, 0.22874452173709803, -2.2...       2         [2765]   \n",
       "23  [-0.212677419185638, 0.457284778356552, -2.437...       2         [2765]   \n",
       "24  [-0.25142347812652505, 0.23143696784973103, -2...       2         [2765]   \n",
       "\n",
       "   pos_cosine_sum  \n",
       "5         [17957]  \n",
       "17         [2765]  \n",
       "18         [2765]  \n",
       "23         [2765]  \n",
       "24         [2765]  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "min_ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
