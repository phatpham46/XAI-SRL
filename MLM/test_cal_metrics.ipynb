{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-19 15:52:09.735950: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-19 15:52:09.953553: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-19 15:52:11.600370: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "2024-05-19 15:52:14.188608: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name:  bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [04:24<00:00,  5.41s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from data_maker import DataMaker\n",
    "model_file = Path('/mnt/c/Users/Phat Pham/Documents/THESIS/SRLPredictionEasel/output/multi_task_model_9_13050.pt')\n",
    "dataMaskDir = Path('/mnt/c/Users/Phat Pham/Documents/THESIS/SRLPredictionEasel/MLM/data_mlm/pertured_data/masked_data_json_v2')\n",
    "dataMaker = DataMaker(\n",
    "    data_file= os.path.join(dataMaskDir,'pertured_data_alter_full.json'),\n",
    "    out_dir= os.path.join(dataMaskDir,'data_predictions'),\n",
    "    saved_model_path=model_file\n",
    ")\n",
    "\n",
    "resultwordMasked  = dataMaker.get_predictions(is_masked=True)\n",
    "resultwordMasked = {\n",
    "    'uid': resultwordMasked[0],\n",
    "    'pred': resultwordMasked[1],\n",
    "    'score': resultwordMasked[2],\n",
    "    'logitsSoftmax': resultwordMasked[3],\n",
    "    'logitsRaw': resultwordMasked[4]    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resultwordMasked['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name:  bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:09<00:00,  4.04s/it]\n"
     ]
    }
   ],
   "source": [
    "dataOriginDir = Path('/mnt/c/Users/Phat Pham/Documents/THESIS/SRLPredictionEasel/MLM/data_mlm/process_folder/mlm_output')\n",
    "dataMaker = DataMaker(\n",
    "    data_file= os.path.join(dataOriginDir,'mlm_abolish_full.json'),\n",
    "    out_dir= os.path.join(dataOriginDir, 'data_predictions'),\n",
    "    saved_model_path=model_file\n",
    ")\n",
    "\n",
    "resultwordOrigin  = dataMaker.get_predictions(is_masked=False)\n",
    "resultwordOrigin = {\n",
    "    'uid': resultwordOrigin[0],\n",
    "    'pred': resultwordOrigin[1],\n",
    "    'score': resultwordOrigin[2],\n",
    "    'logitsSoftmax': resultwordOrigin[3],\n",
    "    'logitsRaw': resultwordOrigin[4]    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'B-A1': 0,\n",
    " 'I-A1': 1,\n",
    " 'O': 2,\n",
    " 'B-V': 3,\n",
    " 'B-A0': 4,\n",
    " 'I-A0': 5,\n",
    " 'B-A4': 6,\n",
    " 'I-A4': 7,\n",
    " 'I-A3': 8,\n",
    " 'B-A2': 9,\n",
    " 'I-A2': 10,\n",
    " 'B-A3': 11,\n",
    " '[CLS]': 12,\n",
    " '[SEP]': 13,\n",
    " 'X': 14}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def get_idx_arg_preds(preds_origin, preds_masked, label_origin=None): # label_origin: nhãn gold\n",
    "    list_idx_arg_change = []\n",
    "    print(len(preds_origin), len(preds_masked ))\n",
    "    assert len(preds_origin) == len(preds_masked), 'Length of preds_origin and preds_masked must be the same'\n",
    "    for i in range(len(preds_origin)):\n",
    "        test = preds_origin[i] not in [2, 3, 12, 13, 14] and preds_masked[i] not in [2, 3, 12, 13, 14]\n",
    "        if label_origin:\n",
    "            assert len(preds_origin) == len(label_origin), 'Length of preds_origin and label_origin must be the same'\n",
    "            if test or label_origin[i] not in [2, 3, 12, 13, 14]:\n",
    "                list_idx_arg_change.append(i)\n",
    "        else:\n",
    "            if test:\n",
    "                list_idx_arg_change.append(i)\n",
    "    return list_idx_arg_change\n",
    "\n",
    "def calculateInfluenceScore(outLogitsSigmoid_original, outLogitsSigmoid_meddle, list_arg_change):\n",
    "    influence_score = []\n",
    "    weight = []\n",
    "    assert len(outLogitsSigmoid_original) == len(outLogitsSigmoid_meddle) \n",
    "    for i in range(len(outLogitsSigmoid_original)):\n",
    "        if i not in list_arg_change:\n",
    "            continue\n",
    "        max_index_original = torch.argmax(outLogitsSigmoid_original[i])\n",
    "        max_index_meddle = torch.argmax(outLogitsSigmoid_meddle[i])\n",
    "        if max_index_original == max_index_meddle:\n",
    "            influence_score.append((outLogitsSigmoid_original[i][max_index_original] - outLogitsSigmoid_meddle[i][max_index_meddle]) / max(outLogitsSigmoid_original[i][max_index_original], outLogitsSigmoid_meddle[i][max_index_meddle]))\n",
    "            weight.append(1)\n",
    "        else:\n",
    "            influ_old_label = (outLogitsSigmoid_original[i][max_index_original] - outLogitsSigmoid_meddle[i][max_index_original]) / max(outLogitsSigmoid_original[i][max_index_original], outLogitsSigmoid_meddle[i][max_index_original])\n",
    "            influ_new_label = (outLogitsSigmoid_meddle[i][max_index_meddle] - outLogitsSigmoid_original[i][max_index_meddle]) / max(outLogitsSigmoid_original[i][max_index_meddle], outLogitsSigmoid_meddle[i][max_index_meddle])\n",
    "            influence_score.append(influ_old_label + influ_new_label)\n",
    "            weight.append(2)\n",
    "    return influence_score, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "sum(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resultwordOrigin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresultwordOrigin\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muid\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m666\u001b[39m], resultwordMasked[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muid\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m683\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resultwordOrigin' is not defined"
     ]
    }
   ],
   "source": [
    "print(resultwordOrigin['uid'][666], resultwordMasked['uid'][683])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13662/2814686101.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  resultwordOrigin['logitsSoftmax'][i] = torch.tensor(resultwordOrigin['logitsSoftmax'][i])\n",
      "/tmp/ipykernel_13662/2814686101.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  resultwordMasked['logitsSoftmax'][i] = torch.tensor(resultwordMasked['logitsSoftmax'][i])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Length of preds_origin and preds_masked must be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(resultwordMasked[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogitsSoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[1;32m      5\u001b[0m     resultwordMasked[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogitsSoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(resultwordMasked[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogitsSoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m][i])\n\u001b[0;32m----> 7\u001b[0m influenceScore, weight \u001b[38;5;241m=\u001b[39m calculateInfluenceScore(resultwordOrigin[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogitsSoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m666\u001b[39m], resultwordMasked[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogitsSoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m683\u001b[39m], \u001b[43mget_idx_arg_preds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresultwordOrigin\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m666\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresultwordMasked\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m683\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn [10], line 7\u001b[0m, in \u001b[0;36mget_idx_arg_preds\u001b[0;34m(preds_origin, preds_masked, label_origin)\u001b[0m\n\u001b[1;32m      5\u001b[0m list_idx_arg_change \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(preds_origin), \u001b[38;5;28mlen\u001b[39m(preds_masked ))\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(preds_origin) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(preds_masked), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLength of preds_origin and preds_masked must be the same\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(preds_origin)):\n\u001b[1;32m      9\u001b[0m     test \u001b[38;5;241m=\u001b[39m preds_origin[i] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m14\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m preds_masked[i] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m14\u001b[39m]\n",
      "\u001b[0;31mAssertionError\u001b[0m: Length of preds_origin and preds_masked must be the same"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "for i in range(len(resultwordOrigin['logitsSoftmax'])):\n",
    "    resultwordOrigin['logitsSoftmax'][i] = torch.tensor(resultwordOrigin['logitsSoftmax'][i])\n",
    "for i in range(len(resultwordMasked['logitsSoftmax'])):\n",
    "    resultwordMasked['logitsSoftmax'][i] = torch.tensor(resultwordMasked['logitsSoftmax'][i])\n",
    "    \n",
    "influenceScore, weight = calculateInfluenceScore(resultwordOrigin['logitsSoftmax'][666], resultwordMasked['logitsSoftmax'][683], get_idx_arg_preds(resultwordOrigin['pred'][666], resultwordMasked['pred'][683]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "min_ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
