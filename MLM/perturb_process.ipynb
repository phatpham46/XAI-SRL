{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tạo pertured data và lưu giống data cũ (cal_metric.py)\n",
    "    1. Tạo ra câu pertured va convert json và ghép label (pertured_folder/masked_data_json)\n",
    "### 2. Lấy ra vector logit \n",
    "    1. convert interim -> txt \n",
    "    2. transform, prepare -> json \n",
    "    3. đưa json (masked data 0.1) vào model lấy logit, prediction -> cần tạo class để lấy cho cả origin data và masked data\n",
    "### 3. convert label gold theo từ thành label gold theo token\n",
    "### 4. Tính inf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Done\n",
    "# convert csv to coNLL format and write to txt file\n",
    "!python ../data_transformations.py --transform_file '/mnt/c/Users/Phat Pham/Documents/THESIS/SRLPredictionEasel/SRL/transform_file_mlm.yml'\n",
    "# output file MLM/coNLL_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Done\n",
    "!python ../data_transformations.py --transform_file '/mnt/c/Users/Phat Pham/Documents/THESIS/SRLPredictionEasel/SRL/transform_file_conll.yml'\n",
    "# nhớ chỉnh lại đường dẫn trong file transform_file_conll.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Done\n",
    "# !python ../data_preparation.py --task_file tasks_file_SRL.yml --data_dir ../data/coNLL_tsv --max_seq_len 50\n",
    "\n",
    "!python ../data_preparation.py \\\n",
    "        --task_file \"/mnt/c/Users/Phat Pham/Documents/THESIS/SRLPredictionEasel/SRL/tasks_file_SRL.yml\" \\\n",
    "        --data_dir ../MLM/coNLL_tsv_json \\\n",
    "        --max_seq_len 85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation influence, relevance and competence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "2024-06-12 14:36:47.433226: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-12 14:36:47.478601: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-12 14:36:48.166853: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-06-12 14:36:48.969472: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "100%|███████████████████████████████████████████| 32/32 [02:16<00:00,  4.27s/it]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:19<00:00,  4.88s/it]\n",
      "lhs shape:  (1024, 5)\n",
      "all_inf_score shape:  1022\n",
      "Traceback (most recent call last):\n",
      "  File \"metrics_calculation.py\", line 191, in <module>\n",
      "    main()\n",
      "  File \"metrics_calculation.py\", line 180, in main\n",
      "    print(\"all_inf_score shape: \", len(all_inf_score[0]))\n",
      "TypeError: object of type 'numpy.float64' has no len()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python metrics_calculation.py \\\n",
    "    --data_mask_dir './data_mlm/perturbed_data/avg_neg_cos/' \\\n",
    "    --data_origin_dir './data_mlm/process_folder/coNLL_tsv_json/ner_json/'  \\\n",
    "    --model_path '../output/multi_task_model_9_13050.pt' \\\n",
    "    --log_name \"cal_corr_inf_lhs\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate metrics for replace mask token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python metrics_calculation.py \\\n",
    "    --data_mask_dir './data_mlm/process_folder/mlm_output/' \\\n",
    "    --data_origin_dir './data_mlm/process_folder/coNLL_tsv_json/ner_json/'  \\\n",
    "    --model_path '../output/multi_task_model_9_13050.pt' \\\n",
    "    --log_name \"comp_mask_token\" \\\n",
    "    --is_mask_token True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate metrics for delete mask token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python metrics_calculation.py \\\n",
    "    --data_mask_dir './data_mlm/process_folder/mlm_output/' \\\n",
    "    --data_origin_dir './data_mlm/process_folder/coNLL_tsv_json/ner_json/'  \\\n",
    "    --model_path '../output/multi_task_model_9_13050.pt' \\\n",
    "    --log_name \"comp_del_mask_token\" \\\n",
    "    --del_mask_token True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:12<00:00,  4.15s/it]\n",
      "100%|██████████| 4/4 [00:22<00:00,  5.62s/it]\n",
      "100%|██████████| 49/49 [03:37<00:00,  4.43s/it]\n",
      "100%|██████████| 5/5 [00:28<00:00,  5.70s/it]\n",
      "100%|██████████| 69/69 [05:14<00:00,  4.55s/it]\n",
      "100%|██████████| 6/6 [00:38<00:00,  6.42s/it]\n",
      "100%|██████████| 110/110 [07:36<00:00,  4.15s/it]\n",
      "100%|██████████| 8/8 [00:48<00:00,  6.10s/it]\n",
      "100%|██████████| 72/72 [04:46<00:00,  3.98s/it]\n",
      "100%|██████████| 6/6 [00:42<00:00,  7.01s/it]\n",
      "100%|██████████| 64/64 [04:28<00:00,  4.19s/it]\n",
      "100%|██████████| 4/4 [00:21<00:00,  5.40s/it]\n",
      "100%|██████████| 94/94 [06:26<00:00,  4.11s/it]\n",
      "100%|██████████| 8/8 [00:52<00:00,  6.56s/it]\n",
      "100%|██████████| 101/101 [07:23<00:00,  4.39s/it]\n",
      "100%|██████████| 9/9 [00:47<00:00,  5.28s/it]\n",
      "100%|██████████| 17/17 [01:06<00:00,  3.93s/it]\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.65s/it]\n",
      "100%|██████████| 29/29 [01:58<00:00,  4.09s/it]\n",
      "100%|██████████| 3/3 [00:13<00:00,  4.58s/it]\n",
      "100%|██████████| 74/74 [05:21<00:00,  4.35s/it]\n",
      "100%|██████████| 6/6 [00:33<00:00,  5.65s/it]\n",
      "100%|██████████| 25/25 [01:46<00:00,  4.25s/it]\n",
      "100%|██████████| 3/3 [00:14<00:00,  4.91s/it]\n",
      "100%|██████████| 28/28 [02:11<00:00,  4.70s/it]\n",
      "100%|██████████| 3/3 [00:20<00:00,  6.96s/it]\n",
      "100%|██████████| 37/37 [02:49<00:00,  4.57s/it]\n",
      "100%|██████████| 4/4 [00:18<00:00,  4.75s/it]\n",
      "100%|██████████| 51/51 [03:14<00:00,  3.80s/it]\n",
      "100%|██████████| 5/5 [00:26<00:00,  5.36s/it]\n",
      "100%|██████████| 31/31 [02:03<00:00,  3.99s/it]\n",
      "100%|██████████| 4/4 [00:18<00:00,  4.70s/it]\n",
      "100%|██████████| 52/52 [03:19<00:00,  3.84s/it]\n",
      "100%|██████████| 5/5 [00:20<00:00,  4.13s/it]\n",
      "100%|██████████| 72/72 [04:47<00:00,  4.00s/it]\n",
      "100%|██████████| 6/6 [00:29<00:00,  4.87s/it]\n",
      "100%|██████████| 44/44 [02:32<00:00,  3.47s/it]\n",
      "100%|██████████| 4/4 [00:18<00:00,  4.65s/it]\n",
      "100%|██████████| 78/78 [04:31<00:00,  3.48s/it]\n",
      "100%|██████████| 7/7 [00:30<00:00,  4.42s/it]\n",
      "100%|██████████| 91/91 [05:58<00:00,  3.94s/it]\n",
      "100%|██████████| 8/8 [00:46<00:00,  5.84s/it]\n",
      " 67%|██████▋   | 132/198 [08:26<04:38,  4.22s/it]"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "from mlm_utils.transform_func import get_files\n",
    "from metrics_calculation import get_pair_inf_rel\n",
    "from data_maker import DataMaker\n",
    "from infer_pipeline import inferPipeline\n",
    "from logger_ import make_logger\n",
    "def get_word(dataDir, file_name, model, labelRn, wrtDir=None, hasTrueLabels=True, needMetrics=True, is_mask_token=False, del_mask_token=False):\n",
    "    dataMaker = DataMaker(\n",
    "        data_file= os.path.join(dataDir, file_name)\n",
    "    )\n",
    "    \n",
    "    result = dataMaker.evaluate(model, labelRn, wrtPredPath=file_name, wrtDir=wrtDir, returnPreds=True, hasTrueLabels=hasTrueLabels, needMetrics=needMetrics, is_mask_token=is_mask_token, del_mask_token=del_mask_token)\n",
    "    return {\n",
    "        'uid': result[0],\n",
    "        'pred': result[1],\n",
    "        'score': result[2],\n",
    "        'logitsSoftmax': result[3],\n",
    "        'logitsRaw': result[4],\n",
    "        'label': result[5] # masked word kh cos label\n",
    "    }\n",
    "    \n",
    "dataMaskedDir = './data_mlm/perturbed_data/avg_pos_cos_module/'\n",
    "dataOriginDir = './data_mlm/process_folder/coNLL_tsv_json/ner_json/'\n",
    "# mask = 'abolish.json' \n",
    "# origin = 'ner_conll_format_abolish_full.json'\n",
    "model_path = '../output/multi_task_model_9_13050.pt'\n",
    "# setting logging\n",
    "now = datetime.now()\n",
    "logDir = now.strftime(\"%d_%m-%H_%M\")\n",
    "if not os.path.isdir(logDir):\n",
    "    os.makedirs(logDir)\n",
    "\n",
    "logger = make_logger(name = 'test_corr_inf_lhs', debugMode=True,\n",
    "                    logFile=os.path.join(logDir, '{}.log'.format('test_corr_inf_lhs')), silent=True)\n",
    "logger.info(\"logger created.\")\n",
    "\n",
    "\n",
    "pipe = inferPipeline(logger, model_path)\n",
    "labelMap = pipe.taskParams.labelMap['conllsrl']\n",
    "labelRn = {v:k for k,v in labelMap.items()}\n",
    " \n",
    "file_mask = sorted(get_files(dataMaskedDir))\n",
    "file_origin = sorted(get_files(dataOriginDir))\n",
    "all_inf_score = []\n",
    "\n",
    "for mask, origin in zip(file_mask, file_origin):   \n",
    "    resultwordMasked = get_word(dataMaskedDir, mask, pipe.model, labelRn, hasTrueLabels=False, needMetrics=False, is_mask_token=False, del_mask_token=False)\n",
    "    resultOrigin = get_word(dataOriginDir, origin, pipe.model, labelRn, hasTrueLabels=True, needMetrics=False)\n",
    "\n",
    "    # labelMap = {v: k for k, v in labelRn.items()}\n",
    "    comp_score, list_inf_score = get_pair_inf_rel(resultOrigin, resultwordMasked, labelMap)\n",
    "    all_inf_score.append(list_inf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1022"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_inf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cos_sim</th>\n",
       "      <th>cos_mo</th>\n",
       "      <th>cos_dif</th>\n",
       "      <th>cos_mo_dif</th>\n",
       "      <th>ele_sub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00674</td>\n",
       "      <td>0.00590</td>\n",
       "      <td>0.99326</td>\n",
       "      <td>0.99410</td>\n",
       "      <td>0.00934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.06479</td>\n",
       "      <td>-0.05743</td>\n",
       "      <td>0.93521</td>\n",
       "      <td>0.94257</td>\n",
       "      <td>0.01097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02651</td>\n",
       "      <td>0.02541</td>\n",
       "      <td>0.97349</td>\n",
       "      <td>0.97459</td>\n",
       "      <td>0.03559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.00867</td>\n",
       "      <td>-0.00758</td>\n",
       "      <td>0.99133</td>\n",
       "      <td>0.99242</td>\n",
       "      <td>0.02029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.09000</td>\n",
       "      <td>-0.07904</td>\n",
       "      <td>0.91000</td>\n",
       "      <td>0.92096</td>\n",
       "      <td>0.01182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cos_sim   cos_mo  cos_dif  cos_mo_dif  ele_sub\n",
       "0  0.00674  0.00590  0.99326     0.99410  0.00934\n",
       "1 -0.06479 -0.05743  0.93521     0.94257  0.01097\n",
       "2  0.02651  0.02541  0.97349     0.97459  0.03559\n",
       "3 -0.00867 -0.00758  0.99133     0.99242  0.02029\n",
       "4 -0.09000 -0.07904  0.91000     0.92096  0.01182"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv \n",
    "import pandas as pd\n",
    "\n",
    "cosin_dir = './data_mlm/process_folder/cosine_similarity'\n",
    "\n",
    "files = get_files(cosin_dir)\n",
    "\n",
    "all_cosine = pd.DataFrame()\n",
    "for file in files:\n",
    "    cos = pd.read_csv(os.path.join(cosin_dir, file))\n",
    "    all_cosine = pd.concat([all_cosine, cos], axis=0, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_cosine['cos_sim'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05535127790642139 0.07694380682028741\n"
     ]
    }
   ],
   "source": [
    "# cal spearman correlation between list_inf_score and cos['cos_sim']\n",
    "from scipy.stats import spearmanr\n",
    "correlation_coefficient, p_value = spearmanr(list_inf_score, cos['cos_mo_dif'][:-2].tolist())\n",
    "print(correlation_coefficient, p_value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "min_ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
