{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation for SRL task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../data_transformations.py --transform_file 'transform_file_pasbio.yml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation for SRL task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../srldata_preparation.py --task_file tasks_file_SRL.yml --data_dir ../data/coNLL_tsv --max_seq_len 85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning BioBERT for SRL task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../train.py \\\n",
    "    --data_dir '../data/coNLL_tsv/dmis-lab/biobert-base-cased-v1.2_prepared_data' \\\n",
    "    --task_file 'tasks_file_SRL.yml' \\\n",
    "    --out_dir '../output/ ' \\\n",
    "    --epochs 10 \\\n",
    "    --train_batch_size 32 \\\n",
    "    --eval_batch_size 32 \\\n",
    "    --grad_accumulation_steps 1 \\\n",
    "    --log_per_updates 50 \\\n",
    "    --max_seq_len 85 \\\n",
    "    --eval_while_train \\\n",
    "    --test_while_train \\\n",
    "    --silent \\\n",
    "    # --load_saved_model '/mnt/c/Users/Phat Pham/Documents/THESIS/SRLPredictionEasel/output/multi_task_model_9_13050.pt'\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
